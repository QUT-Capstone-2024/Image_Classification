{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 5250\n",
      "Training set size: 3675\n",
      "Validation set size: 787\n",
      "Test set size: 788\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "dataset_path = r'c:\\Users\\asuka\\Downloads\\archive\\House_Room_Dataset'\n",
    "categories = ['Bathroom', 'Bedroom', 'Dinning', 'Kitchen', 'Livingroom']\n",
    "IMAGE_SIZE = (128, 128)\n",
    "batch_size = 256\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Function to load and preprocess images with center cropping\n",
    "def load_and_preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.central_crop(image, central_fraction=0.8)  # Center crop the image\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "label_map = {category: idx for idx, category in enumerate(categories)}\n",
    "\n",
    "for category in categories:\n",
    "    category_files = glob.glob(os.path.join(dataset_path, category, '*.jpg')) + glob.glob(os.path.join(dataset_path, category, '*.png'))\n",
    "    image_paths.extend(category_files)\n",
    "    labels.extend([label_map[category]] * len(category_files))\n",
    "\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(image_paths, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n",
    "\n",
    "print(f'Total images: {len(image_paths)}')\n",
    "print(f'Training set size: {len(train_paths)}')\n",
    "print(f'Validation set size: {len(val_paths)}')\n",
    "print(f'Test set size: {len(test_paths)}')\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
    "\n",
    "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Augmentation operations\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def apply_augmentation(image, label):\n",
    "    return data_augmentation(image, training=True), label\n",
    "\n",
    "# Apply augmentation to the training dataset\n",
    "train_ds = train_ds.map(apply_augmentation, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asuka\\AppData\\Local\\Temp\\ipykernel_19164\\1144172524.py:10: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=inputs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_mobilenetv2_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    \n",
    "    # Unfreeze layers for fine-tuning\n",
    "    for layer in base_model.layers[-10:]:  # Unfreeze the last 10 layers\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "num_classes = len(categories)\n",
    "\n",
    "# Create and compile the MobileNetV2 model\n",
    "model = create_mobilenetv2_model(input_shape=(*IMAGE_SIZE, 3), num_classes=num_classes)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 6s/step - accuracy: 0.2275 - loss: 1.9572 - val_accuracy: 0.2745 - val_loss: 1.8463\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.4137 - loss: 1.3964 - val_accuracy: 0.3050 - val_loss: 1.9142\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.5352 - loss: 1.1664 - val_accuracy: 0.3291 - val_loss: 2.1658\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.6023 - loss: 1.0054 - val_accuracy: 0.3545 - val_loss: 2.3289\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 6s/step - accuracy: 0.6557 - loss: 0.9012 - val_accuracy: 0.3647 - val_loss: 2.4895\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 6s/step - accuracy: 0.6946 - loss: 0.8061 - val_accuracy: 0.4028 - val_loss: 2.5202\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.7105 - loss: 0.7557 - val_accuracy: 0.4206 - val_loss: 2.4605\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.7330 - loss: 0.6964 - val_accuracy: 0.4524 - val_loss: 2.2036\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.7749 - loss: 0.6091 - val_accuracy: 0.4930 - val_loss: 2.0971\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.7886 - loss: 0.5704 - val_accuracy: 0.5019 - val_loss: 2.1629\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.7965 - loss: 0.5469 - val_accuracy: 0.5248 - val_loss: 2.1309\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.8252 - loss: 0.4871 - val_accuracy: 0.5591 - val_loss: 1.8598\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.8191 - loss: 0.4759 - val_accuracy: 0.6010 - val_loss: 1.6915\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.8311 - loss: 0.4469 - val_accuracy: 0.6137 - val_loss: 1.7047\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.8514 - loss: 0.4029 - val_accuracy: 0.6328 - val_loss: 1.5469\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.8680 - loss: 0.3696 - val_accuracy: 0.6302 - val_loss: 1.5117\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.8778 - loss: 0.3431 - val_accuracy: 0.6442 - val_loss: 1.5084\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.8713 - loss: 0.3334 - val_accuracy: 0.6569 - val_loss: 1.4211\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 6s/step - accuracy: 0.8800 - loss: 0.3388 - val_accuracy: 0.6722 - val_loss: 1.4067\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 6s/step - accuracy: 0.8956 - loss: 0.2898 - val_accuracy: 0.6747 - val_loss: 1.3808\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9007 - loss: 0.2825 - val_accuracy: 0.6963 - val_loss: 1.3493\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9132 - loss: 0.2292 - val_accuracy: 0.7128 - val_loss: 1.3679\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9223 - loss: 0.2210 - val_accuracy: 0.7141 - val_loss: 1.3569\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9258 - loss: 0.2167 - val_accuracy: 0.7141 - val_loss: 1.3811\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9355 - loss: 0.1859 - val_accuracy: 0.7217 - val_loss: 1.3297\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9435 - loss: 0.1797 - val_accuracy: 0.7408 - val_loss: 1.2098\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9351 - loss: 0.1687 - val_accuracy: 0.7408 - val_loss: 1.2317\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9421 - loss: 0.1544 - val_accuracy: 0.7497 - val_loss: 1.2859\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9524 - loss: 0.1353 - val_accuracy: 0.7446 - val_loss: 1.2753\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9514 - loss: 0.1362 - val_accuracy: 0.7459 - val_loss: 1.3102\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9554 - loss: 0.1293 - val_accuracy: 0.7535 - val_loss: 1.3435\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9618 - loss: 0.1157 - val_accuracy: 0.7471 - val_loss: 1.3718\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9643 - loss: 0.0970 - val_accuracy: 0.7510 - val_loss: 1.3387\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9704 - loss: 0.0864 - val_accuracy: 0.7395 - val_loss: 1.3940\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9704 - loss: 0.0821 - val_accuracy: 0.7484 - val_loss: 1.4472\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9776 - loss: 0.0734 - val_accuracy: 0.7484 - val_loss: 1.4548\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9748 - loss: 0.0703 - val_accuracy: 0.7535 - val_loss: 1.4320\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9781 - loss: 0.0679 - val_accuracy: 0.7471 - val_loss: 1.3824\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9711 - loss: 0.0807 - val_accuracy: 0.7624 - val_loss: 1.3838\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 6s/step - accuracy: 0.9832 - loss: 0.0543 - val_accuracy: 0.7332 - val_loss: 1.4740\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9764 - loss: 0.0679 - val_accuracy: 0.7560 - val_loss: 1.3627\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9786 - loss: 0.0721 - val_accuracy: 0.7548 - val_loss: 1.3238\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 6s/step - accuracy: 0.9800 - loss: 0.0587 - val_accuracy: 0.7764 - val_loss: 1.1655\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9750 - loss: 0.0716 - val_accuracy: 0.7726 - val_loss: 1.2505\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9835 - loss: 0.0558 - val_accuracy: 0.7776 - val_loss: 1.1988\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9790 - loss: 0.0499 - val_accuracy: 0.7878 - val_loss: 1.1201\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9830 - loss: 0.0477 - val_accuracy: 0.7827 - val_loss: 1.2078\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9861 - loss: 0.0442 - val_accuracy: 0.7738 - val_loss: 1.3280\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.9860 - loss: 0.0433 - val_accuracy: 0.7700 - val_loss: 1.3602\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9869 - loss: 0.0402 - val_accuracy: 0.7662 - val_loss: 1.3631\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 741ms/step - accuracy: 0.7771 - loss: 1.4525\n",
      "Test Accuracy: 77.03%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model_mobilenetv2_house_rooms.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50,  \n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Evaluate on test data\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_ds)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Evaluate on train data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Function to compute top-k accuracy\n",
    "def top_k_accuracy(y_true, y_pred, k=1):\n",
    "    top_k_predictions = np.argsort(y_pred, axis=1)[:, -k:]\n",
    "    matches = np.any(top_k_predictions.T == y_true, axis=0)\n",
    "    return np.mean(matches)\n",
    "\n",
    "# Function to plot Cumulative Match Characteristic (CMC)\n",
    "def plot_cmc(y_true, y_pred, num_classes):\n",
    "    cmc = np.zeros(num_classes)\n",
    "    for i in range(1, num_classes + 1):\n",
    "        cmc[i-1] = top_k_accuracy(y_true, y_pred, k=i)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_classes + 1), cmc, marker='o', linestyle='--')\n",
    "    plt.xlabel('Rank')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Cumulative Match Characteristic (CMC)')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Evaluate on train data\n",
    "train_loss, train_acc = model.evaluate(train_ds)\n",
    "print(f\"Train Accuracy: {train_acc * 100:.2f}%\")\n",
    "\n",
    "# Generate predictions and true labels for the test data\n",
    "test_predictions = model.predict(test_ds)\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "test_true_classes = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# Generate predictions and true labels for the train data\n",
    "train_predictions = model.predict(train_ds)\n",
    "train_predicted_classes = np.argmax(train_predictions, axis=1)\n",
    "train_true_classes = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "\n",
    "# Ensure predictions are probabilities\n",
    "if np.max(test_predictions) > 1 or np.min(test_predictions) < 0 or not np.allclose(np.sum(test_predictions, axis=1), 1):\n",
    "    test_predictions = tf.nn.softmax(test_predictions).numpy()\n",
    "if np.max(train_predictions) > 1 or np.min(train_predictions) < 0 or not np.allclose(np.sum(train_predictions, axis=1), 1):\n",
    "    train_predictions = tf.nn.softmax(train_predictions).numpy()\n",
    "\n",
    "# Calculate top-1, top-5, and top-10 accuracy for test data\n",
    "top_1_acc = top_k_accuracy(test_true_classes, test_predictions, k=1)\n",
    "top_5_acc = top_k_accuracy(test_true_classes, test_predictions, k=5)\n",
    "top_10_acc = top_k_accuracy(test_true_classes, test_predictions, k=10)\n",
    "\n",
    "print(f\"Top-1 Accuracy: {top_1_acc * 100:.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc * 100:.2f}%\")\n",
    "print(f\"Top-10 Accuracy: {top_10_acc * 100:.2f}%\")\n",
    "\n",
    "# Plot CMC for test data\n",
    "plot_cmc(test_true_classes, test_predictions, num_classes)\n",
    "\n",
    "# Generate confusion matrix for test data\n",
    "test_cm = confusion_matrix(test_true_classes, test_predicted_classes)\n",
    "\n",
    "# Generate confusion matrix for train data\n",
    "train_cm = confusion_matrix(train_true_classes, train_predicted_classes)\n",
    "\n",
    "# Normalize confusion matrices\n",
    "test_cm_normalized = test_cm.astype('float') / test_cm.sum(axis=1)[:, np.newaxis]\n",
    "train_cm_normalized = train_cm.astype('float') / train_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot normalized confusion matrix for test data\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(test_cm_normalized, annot=True, fmt='.2f', cmap='coolwarm', cbar=True, linewidths=0.5, linecolor='black')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title(f'Test Confusion Matrix (Accuracy: {test_acc * 100:.2f}%)')\n",
    "plt.xticks(ticks=np.arange(num_classes) + 0.5, labels=np.arange(num_classes), rotation=90)\n",
    "plt.yticks(ticks=np.arange(num_classes) + 0.5, labels=np.arange(num_classes), rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix for train data\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(train_cm_normalized, annot=True, fmt='.2f', cmap='coolwarm', cbar=True, linewidths=0.5, linecolor='black')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title(f'Train Confusion Matrix (Accuracy: {train_acc * 100:.2f}%)')\n",
    "plt.xticks(ticks=np.arange(num_classes) + 0.5, labels=np.arange(num_classes), rotation=90)\n",
    "plt.yticks(ticks=np.arange(num_classes) + 0.5, labels=np.arange(num_classes), rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Print classification report for test data\n",
    "print(classification_report(test_true_classes, test_predicted_classes))\n",
    "\n",
    "# AUC ROC for test data\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_true_classes == i, test_predictions[:, i])\n",
    "    roc_auc[i] = roc_auc_score(test_true_classes == i, test_predictions[:, i])\n",
    "\n",
    "# Plot ROC curve without legend for test data\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve for Test Data')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 788ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: True label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[true_label]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m misclassified as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[pred_label]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m times)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Get class names from metadata\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m class_names \u001b[38;5;241m=\u001b[39m \u001b[43mmetadata\u001b[49m\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Get the top 5 most misclassified labels\u001b[39;00m\n\u001b[0;32m     34\u001b[0m misclassified_labels \u001b[38;5;241m=\u001b[39m most_misclassified(cm, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate predictions and true labels for the test data\n",
    "predictions = model.predict(test_ds)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Calculate the most misclassified labels\n",
    "def most_misclassified(cm, n=5):\n",
    "    # Set the diagonal to zero to ignore true positives\n",
    "    np.fill_diagonal(cm, 0)\n",
    "    # Flatten the confusion matrix and get the indices of the largest values\n",
    "    misclassified_indices = np.unravel_index(np.argsort(cm, axis=None)[-n:], cm.shape)\n",
    "    # Get the misclassified labels\n",
    "    misclassified_labels = [(i, j, cm[i, j]) for i, j in zip(misclassified_indices[0], misclassified_indices[1])]\n",
    "    # Sort by the number of misclassifications\n",
    "    misclassified_labels = sorted(misclassified_labels, key=lambda x: x[2], reverse=True)\n",
    "    return misclassified_labels\n",
    "\n",
    "# Display the most misclassified labels\n",
    "def display_misclassified_labels(misclassified_labels, class_names):\n",
    "    for i, (true_label, pred_label, count) in enumerate(misclassified_labels):\n",
    "        print(f\"Rank {i+1}: True label '{class_names[true_label]}' misclassified as '{class_names[pred_label]}' ({count} times)\")\n",
    "\n",
    "# Get class names from metadata\n",
    "class_names = metadata.features['label'].names\n",
    "\n",
    "# Get the top 5 most misclassified labels\n",
    "misclassified_labels = most_misclassified(cm, n=15)\n",
    "\n",
    "# Display the most misclassified labels\n",
    "display_misclassified_labels(misclassified_labels, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
